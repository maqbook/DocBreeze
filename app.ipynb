{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f6960c-9166-4712-9b82-20aec7a6dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (1.25.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (0.3.28)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (0.2.6)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (2.2.1)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-huggingface) (0.27.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-huggingface) (3.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-huggingface) (4.47.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-ollama) (0.4.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ahzxm\\anaconda3\\envs\\docbreeze\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-community faiss-cpu langchain-huggingface pymupdf tiktoken langchain-ollama python-dotenv langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016c5cdc-410d-484e-aeb1-96593b098415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ebaeb",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e14acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"./rag_dataset/military_docs/Deep_Reinforcement_Learning-Ba.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f2ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[0]\n",
    "# print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b71f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pdfs = []\n",
    "for root, dirs, files in os.walk('rag_dataset'):\n",
    "    # print(root, dirs, files)\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdfs.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151510aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for pdf in pdfs:\n",
    "    loader = PyMuPDFLoader(pdf)\n",
    "    pages = loader.load()\n",
    "    docs.extend(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "415de892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30c324",
   "metadata": {},
   "source": [
    "### Document Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3eff584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1cf8959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 250)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document pages vs chunks\n",
    "len(docs), len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9fbaf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4066, 926)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# character count of first document page vs first chunk page\n",
    "len(docs[0].page_content), len(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de1afe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 242)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "\n",
    "len(encoding.encode(docs[0].page_content)), len(encoding.encode(chunks[0].page_content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7cae1",
   "metadata": {},
   "source": [
    "### Document Vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a05b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89ce9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url=\"http://localhost:11434\")\n",
    "\n",
    "single_vector = embeddings.embed_query(\"rambutan is the best fruit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1358b49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(single_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f48b006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(len(single_vector))\n",
    "index.ntotal, index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab0154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS(\n",
    "    embedding_function = embeddings,\n",
    "    index = index,\n",
    "    docstore = InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45515247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12ef62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed0ebe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c9e2e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vector database\n",
    "# db_name = 'military_info'\n",
    "# vector_store.save_local(db_name)\n",
    "\n",
    "# load the vector database\n",
    "# new_vector_store = FAISS.load_local(db_name, embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d8da7",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66d83ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests and according to the purpose of the GTS system – we dig deeper into \n",
      "the individual and sub-unit infantry training. Considering the current state of \n",
      "development, we present the training areas where the introduction of VR can \n",
      "be particularly beneficial.\n",
      "Keywords: military training, VR, AR, simulation, immersivity\n",
      "Introduction\n",
      "The well-known fact that military developments bring breakthroughs in technology is still \n",
      "true, but some technologies are spreading and refining much faster in the civilian sector. \n",
      "An example of this is VR (virtual reality) technology. Extensive research was done in \n",
      "this area decades ago, but certain boundaries could not be crossed at that time. A major \n",
      "development started when the hardware and software of Oculus’s first VR devices became \n",
      "open source and the potential for entertainment was recognised. As consumer VR devices \n",
      "gained popularity, many companies started to develop headsets and software. Later, these\n",
      "\n",
      "\n",
      "\n",
      "the capabilities of today’s VR technology.\n",
      "Because of the above-described features of VR technology, we state that the primary \n",
      "role of VR training is now at the level of the individual. Therefore, at this level, there is \n",
      "already a wide range of options available.\n",
      "Primarily, where the individual soldier employs a complex machine (tank, bulldozer, \n",
      "aircraft etc.), it is useful to teach the handling of the basic switches and handles in the VR \n",
      "because if something goes wrong, the – usually – expensive asset will get damaged. It is \n",
      "a lot cheaper and easier to build the dashboard of the complex machine in the virtual space \n",
      "and practice procedures multiple times than to use the actual military hardware for basic \n",
      "operator training. Furthermore, there are emergency situations (e.g. fire or explosion) that \n",
      "cannot be practised on the actual equipment.\n",
      "For shooting training, of course, the live fire exercises are indispensable. However,\n",
      "\n",
      "\n",
      "\n",
      "After reviewing the training options in these training types, we have thoroughly \n",
      "examined the VR’s options in the field of individual and sub-unit level infantry tactics \n",
      "training. We have found an enormous number of opportunities where VR can save a lot \n",
      "of time and other resources (money, ammunition, lifespan of weapons, etc.) for the HDF. \n",
      "Furthermore, VR has other advantages regarding the methodology of the training. VR \n",
      "technology enables the difficulty of training to be increased according to the purpose \n",
      "of the unit and the capabilities of the trainees. Furthermore, the training events can be \n",
      "recorded and replayed for more objective assessment and analysis.\n",
      "All in all, we can firmly state that even at the current level of development, VR-based \n",
      "training can have a lot of advantages and can further help the training process if used at \n",
      "the correct level and at the correct phase of the process.\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "training. We think that the greatest opportunity in VR currently is the following:\n",
      "•\t classifying threats and targets\n",
      "•\t practising giving and executing firing orders\n",
      "24\t\n",
      "Department of the Army 2010: 5-3.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"How can VR be used in military training?\"\n",
    "docs = vector_store.search(query=question, search_type='similarity')\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "100874fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='mmr', search_kwargs={'k': 3, 'fetch_k': 100, 'lambda_mult': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fd76c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the conclusion in 3 sentences:\n",
      "\n",
      "The authors conclude that VR has great potential for improving training opportunities in the Hungarian Defence Forces. They identify individual specialist training, sub-unit level training, and crew training as key areas where VR can be effectively implemented. The use of VR devices with natural input and fully simulated environments can provide a realistic experience, leading to more effective training methodologies.\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(question)\n",
    "# for doc in docs:\n",
    "#     print(doc.page_content)\n",
    "#     print(\"\\n\\n\")\n",
    "\n",
    "question = \"Summarize the conclusion of the VR_Training_Opportunities_in_t.pdf document\"\n",
    "docs = retriever.invoke(question)\n",
    "output = rag_chain.invoke(question)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40caf1",
   "metadata": {},
   "source": [
    "### R.A.G w/ LLAMA 3.2 (3b params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34aa966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub # uploading, browsing, pulling & managing prompts\n",
    "from langchain_core.output_parsers import StrOutputParser # gives final output as string data\n",
    "from langchain_core.runnables import RunnablePassthrough # pass question & context directly to the model\n",
    "from langchain_core.prompts import ChatPromptTemplate # pass prompt, context & question\n",
    "\n",
    "from langchain_ollama import ChatOllama # makes connection from your model to langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b24870cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oi back atcha! How's it going?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-30T14:21:53.875334Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2467044500, 'load_duration': 2101779300, 'prompt_eval_count': 27, 'prompt_eval_duration': 233000000, 'eval_count': 12, 'eval_duration': 130000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-94e88595-fd9f-46b8-8e00-0afd48907961-0', usage_metadata={'input_tokens': 27, 'output_tokens': 12, 'total_tokens': 39})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOllama(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "model.invoke(\"oi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49b97ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = hub.pull(\"langchain-ai/rag-fusion-query-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3469898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" \n",
    "You are an assistant for question-answering tasks. \n",
    "Use the following retrieved information to answer the questions. \n",
    "If you don't know, just state that you don't know. Use three sentences maximum, keeping the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eec83a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maroochy wastewater system attack, the Stuxnet worm attack, and the German steel plant\n",
      "attack, have inflicted substantial financial damage on related facilities [3–5]. Recently, a\n",
      "growing number of studies have been dedicated to developing intrusion detection systems\n",
      "aimed at improving the security of industrial control systems [6–10]. Intrusion detection\n",
      "systems continuously monitor the status of the system and provide a warning in the event\n",
      "of an attack, enabling engineers to respond promptly. The accuracy of intrusion detection\n",
      "systems for securing industrial control systems has improved through the use of rule-based\n",
      "approaches [2] and deep learning-based techniques [11].\n",
      "Along with developing algorithms to improve the accuracy of intrusion detection\n",
      "systems, research has also been conducted on methods for generating adversarial attacks\n",
      "to evaluate the performance of intrusion detection systems [12–18]. Among the various\n",
      "\n",
      "to evaluate the performance of intrusion detection systems [12–18]. Among the various\n",
      "methods for adversarial attacks, this paper focuses on man-in-the-middle attacks that\n",
      "manipulate sensor measurements or actuator configurations in industrial control systems.\n",
      "In industrial control systems, a programmable logic controller (PLC) acts as a control device\n",
      "that receives measurements from sensors and determines the configurations for actuators.\n",
      "To carry out a man-in-the-middle attack, an adversarial attacker positions itself between\n",
      "Mathematics 2024, 12, 3900. https://doi.org/10.3390/math12243900\n",
      "https://www.mdpi.com/journal/mathematics\n",
      "\n",
      "intrusion detection systems. Dig. Threat. Res. Pract. 2022, 3, 1–19. [CrossRef]\n",
      "18.\n",
      "Anton, S.D.; Kanoor, S.; Fraunholz, D.; Schotten, H.D. Evaluation of machine learning-based anomaly detection algorithms on an\n",
      "industrial modbus/tcp data set. In Proceedings of the 13th International Conference on Availability, Reliability and Security\n",
      "(ARES’18), New York, NY, USA, 27–30 August 2018; pp. 1–9.\n",
      "19.\n",
      "Mathur, A.P.; Tippenhauer, N.O. SWaT: A water treatment testbed for research and training on ICS security. In Proceedings of the\n",
      "2016 International Workshop on Cyber-Physical Systems for Smart Water Networks (CySWater), Vienna, Austria, 11 April 2016;\n",
      "pp. 31–36.\n",
      "20.\n",
      "Goh, J.; Adepu, S.; Junejo, K.N.; Mathur, A. A dataset to support research in the design of secure water treatment systems. In\n",
      "Proceedings of the Critical Information Infrastructures Security, Paris, France, 10–12 October 2016; pp. 88–99.\n",
      "21.\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "print(format_docs(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "438d1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docbreeze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
